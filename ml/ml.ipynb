{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c77c1f9a-2a9e-4c46-ae7f-002f215ff2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "sys.path.append('../')\n",
    "import fn\n",
    "from addition_dataset import GroupAddition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e1c632-414c-46b3-a7c1-bcdf9d06f54b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb94066-33ea-4bbb-8d4c-33aebccfa958",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "b99bad01-213f-4b08-b678-b911dbcb5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify base, depth (num. digits), carry table, and batch size\n",
    "b = 4\n",
    "depth = 3\n",
    "table = 1*(np.add.outer(np.arange(b),np.arange(b))>=b)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "0f494a4e-4c8f-4f81-b8eb-d1eba178d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of training and testing data\n",
    "split = 0.9\n",
    "N = b**depth\n",
    "ids = random.sample(range(N), math.ceil(split * N))\n",
    "heldout_ids = set(range(N)) - set(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "043215c9-e3d6-4787-b897-f68af193bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset and dataloader\n",
    "num_passes = 1000\n",
    "training_dataset = GroupAddition(table, depth, ids=ids, interleaved=True, digit_order='reversed')\n",
    "training_dataset = torch.utils.data.ConcatDataset([training_dataset] * num_passes)\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create testing dataset and dataloader\n",
    "testing_dataset = GroupAddition(table, depth, ids=heldout_ids, interleaved=True, digit_order='reversed')\n",
    "testing_dataset = torch.utils.data.ConcatDataset([testing_dataset] * num_passes)\n",
    "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88edca88-f9c6-4f30-8d67-7d88ce206ac3",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55fd157-1bd9-48b5-8777-947346ed2d11",
   "metadata": {},
   "source": [
    "### Define model, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "2044b98f-1d03-4eac-af03-b390ba005c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class LSTMModel(nn.Module):\n",
    "    '''Simple LSTM model for testing purposes'''\n",
    "    def __init__(self, b, hidden, layers):\n",
    "        '''Initialize model with specified parameters'''\n",
    "        super().__init__()\n",
    "        self.b = b\n",
    "        self.hidden = hidden\n",
    "        self.layers = layers\n",
    "        self.lstm = nn.LSTM(b, hidden, layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''Return forward-pass including missing values of X'''\n",
    "        X_out, _ = self.lstm(X)\n",
    "        X_out = self.linear(X_out).squeeze()\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "a82b3c65-e770-4067-a42b-8fceb71be921",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(b, b, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "2af33aa9-7a42-4e34-a433-d1383fd619b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_out, ids):\n",
    "    if X_out.dim() == 2:\n",
    "        X_out_and_ids = zip(torch.unbind(X_out), torch.unbind(ids))\n",
    "        s_out = torch.stack([X_out[ids] for X_out, ids in X_out_and_ids])\n",
    "    else:\n",
    "        s_out = X[ids]\n",
    "    return s_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "63add8ce-fab3-4d53-af88-ed8a60a7c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X_out, s, ids):\n",
    "        MSE = nn.MSELoss()\n",
    "        s_out = prediction(X_out, ids)\n",
    "        loss = MSE(s_out, s)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "c33831e3-bf26-447e-ac07-f3919d47ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criterion and optimizer\n",
    "criterion = Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce717502-3ef2-4d2c-adf0-aded96ab6736",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "d8c0867f-0a24-496d-8beb-1b2e7f70f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0  loss = 3.520770\n",
      "t = 100  loss = 1.402542\n",
      "t = 200  loss = 1.189651\n",
      "t = 300  loss = 0.917384\n",
      "t = 400  loss = 1.004953\n",
      "t = 500  loss = 1.176763\n",
      "t = 600  loss = 1.189975\n",
      "t = 700  loss = 0.861677\n",
      "t = 800  loss = 0.742377\n",
      "t = 900  loss = 0.466740\n",
      "t = 1000  loss = 0.148483\n",
      "t = 1100  loss = 0.142234\n",
      "t = 1200  loss = 0.189211\n",
      "t = 1300  loss = 0.072970\n",
      "t = 1400  loss = 0.045127\n",
      "t = 1500  loss = 0.032835\n",
      "t = 1600  loss = 0.029066\n",
      "t = 1700  loss = 0.027149\n",
      "t = 1800  loss = 0.019293\n",
      "t = 1900  loss = 0.015020\n",
      "t = 2000  loss = 0.014234\n",
      "t = 2100  loss = 0.011054\n",
      "t = 2200  loss = 0.011769\n",
      "t = 2300  loss = 0.008884\n",
      "t = 2400  loss = 0.008357\n",
      "t = 2500  loss = 0.005850\n",
      "t = 2600  loss = 0.004397\n",
      "t = 2700  loss = 0.003974\n",
      "t = 2800  loss = 0.003003\n",
      "t = 2900  loss = 0.004802\n",
      "t = 3000  loss = 0.007744\n",
      "t = 3100  loss = 0.003570\n",
      "t = 3200  loss = 0.002575\n",
      "t = 3300  loss = 0.005088\n",
      "t = 3400  loss = 0.001941\n",
      "t = 3500  loss = 0.006714\n",
      "t = 3600  loss = 0.002756\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "t = 0\n",
    "for batch_idx, (X, s, ids) in enumerate(training_dataloader):\n",
    "    \n",
    "    # Compute and print lossq\n",
    "    loss = criterion(model(X), s.float(), ids)\n",
    "    if t % 100 == 0:\n",
    "        print(f't = {t}  loss = {loss.item():.6f}')\n",
    "    \n",
    "    # Zero gradients, perform a backward pass, and update the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Iterate counter\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "d21421f6-add5-4340-b7bb-99ff5853e11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Perform evaluation\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for batch_idx, (X, s, ids) in enumerate(testing_dataloader):\n",
    "\n",
    "        # Forward pass\n",
    "        X_out = model(X)\n",
    "        s_out = prediction(X_out, ids)\n",
    "        s_out = torch.round(s_out)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        total_correct += ((s_out == s).sum(1) == depth).sum().item()\n",
    "        total_samples += batch_size\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Accuracy on testing set: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48306688-e6dd-4a1b-b853-433b6e8fbd1a",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4cfcad-e187-4682-aa01-932d9045f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
